{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import os  \n",
    "import glob\n",
    "from tensorflow.keras import layers, losses\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Layer\n",
    "from tensorflow import keras\n",
    "from pathlib import Path\n",
    "from sklearn.datasets import load_files\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.layers import Lambda\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "latent_dim = 64 \n",
    "\n",
    "class Encoder(Layer):\n",
    "  def __init__(self):\n",
    "    super(Encoder, self).__init__()\n",
    "    self.latent_dim = latent_dim   \n",
    "    self.encoder = tf.keras.Sequential([\n",
    "    \n",
    "      layers.Input(shape=(24, 24, 1)), \n",
    "      layers.Conv2D(16, (6,6), activation='relu', padding='valid', strides=1),\n",
    "      layers.Conv2D(8,(2,2), activation='relu', padding='valid', strides=1)])\n",
    "\n",
    "  def call(self, x):\n",
    "    encoded = self.encoder(x)\n",
    "    return encoded\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Decoder(Layer):\n",
    "  def __init__(self):\n",
    "    super(Decoder, self).__init__()\n",
    "    self.decoder = tf.keras.Sequential([\n",
    "      layers.Conv2DTranspose(8, kernel_size=(2,2), strides=1, activation='relu',padding='valid'),\n",
    "      layers.Conv2DTranspose(16, kernel_size=(6,6), strides=1, activation='relu',padding='valid'),\n",
    "      layers.Conv2D(1, kernel_size=(1,1), activation='sigmoid', padding='valid')])\n",
    "\n",
    "  def call(self, x):\n",
    "    decoded = self.decoder(x)\n",
    "    return decoded\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Autoencoder(Model):\n",
    "    def __init__(self):\n",
    "        super(Autoencoder,self).__init__()\n",
    "        self.Autoencoder=tf.keras.Sequential([\n",
    "            Encoder(),\n",
    "            Decoder()\n",
    "        ])\n",
    "    def call(self,x):\n",
    "        return self.Autoencoder(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "autoencoder = Autoencoder()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "autoencoder.compile(optimizer='adam', loss=losses.MeanSquaredError())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "Full=tf.io.gfile.listdir('24TaxonFull')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "Missing=tf.io.gfile.listdir('24TaxonData')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "FullDataset=[]\n",
    "for i in Full:\n",
    "    name, extension = os.path.splitext('24TaxonFull/'+str(i))\n",
    "    if extension=='.csv':\n",
    "        ReadPanda=pd.read_csv('24TaxonFull/'+str(i))\n",
    "        FullDataset.append(ReadPanda)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "MissingDataset=[]\n",
    "for i in Missing:\n",
    "\n",
    "    name, extension = os.path.splitext('24TaxonData/'+str(i))\n",
    "    if extension=='.csv':\n",
    "        ReadPanda=pd.read_csv('24TaxonData/'+str(i))\n",
    "        MissingDataset.append(ReadPanda)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.shape(np.array(FullDataset))\n",
    "FullDataset=np.array(FullDataset)\n",
    "np.save('FullDataset',FullDataset)\n",
    "np.shape(np.array(MissingDataset))\n",
    "MissingDataset=np.array(MissingDataset)\n",
    "np.save('MissingDataset',MissingDataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1000, 24, 24)"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.shape(MissingDataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1000, 24, 24, 1)"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "FullDataSet=FullDataset[...,tf.newaxis]\n",
    "np.shape(FullDataSet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1000, 24, 24, 1)"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "MissingDataSet=MissingDataset[...,tf.newaxis]\n",
    "np.shape(MissingDataSet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "200/200 [==============================] - 2s 8ms/step - loss: 0.0439\n",
      "Epoch 2/100\n",
      "200/200 [==============================] - 2s 8ms/step - loss: 0.0038\n",
      "Epoch 3/100\n",
      "200/200 [==============================] - 2s 8ms/step - loss: 0.0015\n",
      "Epoch 4/100\n",
      "200/200 [==============================] - 2s 8ms/step - loss: 9.5838e-04\n",
      "Epoch 5/100\n",
      "200/200 [==============================] - 2s 8ms/step - loss: 7.4735e-04\n",
      "Epoch 6/100\n",
      "200/200 [==============================] - 2s 8ms/step - loss: 5.8813e-04\n",
      "Epoch 7/100\n",
      "200/200 [==============================] - 2s 8ms/step - loss: 4.5880e-04\n",
      "Epoch 8/100\n",
      "200/200 [==============================] - 2s 8ms/step - loss: 3.5958e-04\n",
      "Epoch 9/100\n",
      "200/200 [==============================] - 2s 9ms/step - loss: 2.7188e-04\n",
      "Epoch 10/100\n",
      "200/200 [==============================] - 2s 8ms/step - loss: 2.2214e-04\n",
      "Epoch 11/100\n",
      "200/200 [==============================] - 2s 8ms/step - loss: 1.9680e-04\n",
      "Epoch 12/100\n",
      "200/200 [==============================] - 2s 8ms/step - loss: 1.7168e-04\n",
      "Epoch 13/100\n",
      "200/200 [==============================] - 2s 8ms/step - loss: 1.6528e-04\n",
      "Epoch 14/100\n",
      "200/200 [==============================] - 2s 8ms/step - loss: 1.4708e-04\n",
      "Epoch 15/100\n",
      "200/200 [==============================] - 2s 8ms/step - loss: 1.3889e-04\n",
      "Epoch 16/100\n",
      "200/200 [==============================] - 2s 8ms/step - loss: 1.3015e-04\n",
      "Epoch 17/100\n",
      "200/200 [==============================] - 2s 8ms/step - loss: 1.1395e-04\n",
      "Epoch 18/100\n",
      "200/200 [==============================] - 2s 8ms/step - loss: 1.0803e-04\n",
      "Epoch 19/100\n",
      "200/200 [==============================] - 2s 8ms/step - loss: 9.7731e-05\n",
      "Epoch 20/100\n",
      "200/200 [==============================] - 2s 8ms/step - loss: 8.9553e-05\n",
      "Epoch 21/100\n",
      "200/200 [==============================] - 2s 8ms/step - loss: 8.8036e-05\n",
      "Epoch 22/100\n",
      "200/200 [==============================] - 2s 8ms/step - loss: 8.3236e-05\n",
      "Epoch 23/100\n",
      "200/200 [==============================] - 2s 8ms/step - loss: 7.7660e-05\n",
      "Epoch 24/100\n",
      "200/200 [==============================] - 2s 8ms/step - loss: 7.5759e-05\n",
      "Epoch 25/100\n",
      "200/200 [==============================] - 2s 8ms/step - loss: 7.3493e-05\n",
      "Epoch 26/100\n",
      "200/200 [==============================] - 2s 8ms/step - loss: 6.9181e-05\n",
      "Epoch 27/100\n",
      "200/200 [==============================] - 2s 8ms/step - loss: 6.5230e-05\n",
      "Epoch 28/100\n",
      "200/200 [==============================] - 2s 8ms/step - loss: 6.2827e-05\n",
      "Epoch 29/100\n",
      "200/200 [==============================] - 2s 8ms/step - loss: 6.0902e-05\n",
      "Epoch 30/100\n",
      "200/200 [==============================] - 2s 8ms/step - loss: 5.8753e-05\n",
      "Epoch 31/100\n",
      "200/200 [==============================] - 2s 8ms/step - loss: 5.5652e-05\n",
      "Epoch 32/100\n",
      "200/200 [==============================] - 2s 9ms/step - loss: 5.2906e-05\n",
      "Epoch 33/100\n",
      "200/200 [==============================] - 2s 8ms/step - loss: 5.2101e-05\n",
      "Epoch 34/100\n",
      "200/200 [==============================] - 2s 8ms/step - loss: 5.0082e-05\n",
      "Epoch 35/100\n",
      "200/200 [==============================] - 2s 8ms/step - loss: 4.8396e-05\n",
      "Epoch 36/100\n",
      "200/200 [==============================] - 2s 8ms/step - loss: 4.6721e-05\n",
      "Epoch 37/100\n",
      "200/200 [==============================] - 2s 8ms/step - loss: 4.5841e-05\n",
      "Epoch 38/100\n",
      "200/200 [==============================] - 2s 8ms/step - loss: 4.3681e-05\n",
      "Epoch 39/100\n",
      "200/200 [==============================] - 2s 8ms/step - loss: 4.1954e-05\n",
      "Epoch 40/100\n",
      "200/200 [==============================] - 2s 8ms/step - loss: 4.1634e-05\n",
      "Epoch 41/100\n",
      "200/200 [==============================] - 2s 8ms/step - loss: 4.0988e-05\n",
      "Epoch 42/100\n",
      "200/200 [==============================] - 2s 8ms/step - loss: 3.9428e-05\n",
      "Epoch 43/100\n",
      "200/200 [==============================] - 2s 8ms/step - loss: 3.9160e-05\n",
      "Epoch 44/100\n",
      "200/200 [==============================] - 2s 8ms/step - loss: 3.7915e-05\n",
      "Epoch 45/100\n",
      "200/200 [==============================] - 2s 8ms/step - loss: 3.7775e-05\n",
      "Epoch 46/100\n",
      "200/200 [==============================] - 2s 8ms/step - loss: 3.6814e-05\n",
      "Epoch 47/100\n",
      "200/200 [==============================] - 2s 8ms/step - loss: 3.4699e-05\n",
      "Epoch 48/100\n",
      "200/200 [==============================] - 2s 8ms/step - loss: 3.4543e-05\n",
      "Epoch 49/100\n",
      "200/200 [==============================] - 2s 8ms/step - loss: 3.4411e-05\n",
      "Epoch 50/100\n",
      "200/200 [==============================] - 2s 8ms/step - loss: 3.3532e-05\n",
      "Epoch 51/100\n",
      "200/200 [==============================] - 2s 8ms/step - loss: 3.2872e-05\n",
      "Epoch 52/100\n",
      "200/200 [==============================] - 2s 8ms/step - loss: 3.3245e-05\n",
      "Epoch 53/100\n",
      "200/200 [==============================] - 2s 8ms/step - loss: 3.1381e-05\n",
      "Epoch 54/100\n",
      "200/200 [==============================] - 2s 8ms/step - loss: 3.1359e-05\n",
      "Epoch 55/100\n",
      "200/200 [==============================] - 2s 8ms/step - loss: 3.1340e-05\n",
      "Epoch 56/100\n",
      "200/200 [==============================] - 2s 8ms/step - loss: 3.0279e-05\n",
      "Epoch 57/100\n",
      "200/200 [==============================] - 2s 8ms/step - loss: 3.0559e-05\n",
      "Epoch 58/100\n",
      "200/200 [==============================] - 2s 8ms/step - loss: 2.9128e-05\n",
      "Epoch 59/100\n",
      "200/200 [==============================] - 2s 8ms/step - loss: 2.8555e-05\n",
      "Epoch 60/100\n",
      "200/200 [==============================] - 2s 9ms/step - loss: 2.9497e-05\n",
      "Epoch 61/100\n",
      "200/200 [==============================] - 2s 9ms/step - loss: 2.8044e-05\n",
      "Epoch 62/100\n",
      "200/200 [==============================] - 2s 9ms/step - loss: 2.8149e-05\n",
      "Epoch 63/100\n",
      "200/200 [==============================] - 2s 9ms/step - loss: 2.7899e-05\n",
      "Epoch 64/100\n",
      "200/200 [==============================] - 2s 8ms/step - loss: 2.7446e-05\n",
      "Epoch 65/100\n",
      "200/200 [==============================] - 2s 8ms/step - loss: 2.7295e-05\n",
      "Epoch 66/100\n",
      "200/200 [==============================] - 2s 8ms/step - loss: 2.7486e-05\n",
      "Epoch 67/100\n",
      "200/200 [==============================] - 2s 8ms/step - loss: 2.7783e-05\n",
      "Epoch 68/100\n",
      "200/200 [==============================] - 2s 8ms/step - loss: 2.5983e-05\n",
      "Epoch 69/100\n",
      "200/200 [==============================] - 2s 8ms/step - loss: 2.6333e-05\n",
      "Epoch 70/100\n",
      "200/200 [==============================] - 2s 8ms/step - loss: 2.6716e-05\n",
      "Epoch 71/100\n",
      "200/200 [==============================] - 2s 8ms/step - loss: 2.6110e-05\n",
      "Epoch 72/100\n",
      "200/200 [==============================] - 2s 8ms/step - loss: 2.5803e-05\n",
      "Epoch 73/100\n",
      "200/200 [==============================] - 2s 8ms/step - loss: 2.6200e-05\n",
      "Epoch 74/100\n",
      "200/200 [==============================] - 2s 8ms/step - loss: 2.5062e-05\n",
      "Epoch 75/100\n",
      "200/200 [==============================] - 2s 8ms/step - loss: 2.4756e-05\n",
      "Epoch 76/100\n",
      "200/200 [==============================] - 2s 8ms/step - loss: 2.4747e-05\n",
      "Epoch 77/100\n",
      "200/200 [==============================] - 2s 8ms/step - loss: 2.4601e-05\n",
      "Epoch 78/100\n",
      "200/200 [==============================] - 2s 8ms/step - loss: 2.4897e-05\n",
      "Epoch 79/100\n",
      "200/200 [==============================] - 2s 8ms/step - loss: 2.4472e-05\n",
      "Epoch 80/100\n",
      "200/200 [==============================] - 2s 8ms/step - loss: 2.3747e-05\n",
      "Epoch 81/100\n",
      "200/200 [==============================] - 2s 8ms/step - loss: 2.3051e-05\n",
      "Epoch 82/100\n",
      "200/200 [==============================] - 2s 8ms/step - loss: 2.4181e-05\n",
      "Epoch 83/100\n",
      "200/200 [==============================] - 2s 8ms/step - loss: 2.3951e-05\n",
      "Epoch 84/100\n",
      "200/200 [==============================] - 2s 8ms/step - loss: 2.3373e-05\n",
      "Epoch 85/100\n",
      "200/200 [==============================] - 2s 8ms/step - loss: 2.2791e-05\n",
      "Epoch 86/100\n",
      "200/200 [==============================] - 2s 8ms/step - loss: 2.3538e-05\n",
      "Epoch 87/100\n",
      "200/200 [==============================] - 2s 8ms/step - loss: 2.2428e-05\n",
      "Epoch 88/100\n",
      "200/200 [==============================] - 2s 8ms/step - loss: 2.2643e-05\n",
      "Epoch 89/100\n",
      "200/200 [==============================] - 2s 8ms/step - loss: 2.2627e-05\n",
      "Epoch 90/100\n",
      "200/200 [==============================] - 2s 8ms/step - loss: 2.2509e-05\n",
      "Epoch 91/100\n",
      "200/200 [==============================] - 2s 8ms/step - loss: 2.1945e-05\n",
      "Epoch 92/100\n",
      "200/200 [==============================] - 2s 9ms/step - loss: 2.2042e-05\n",
      "Epoch 93/100\n",
      "200/200 [==============================] - 2s 8ms/step - loss: 2.1564e-05\n",
      "Epoch 94/100\n",
      "200/200 [==============================] - 2s 8ms/step - loss: 2.1893e-05\n",
      "Epoch 95/100\n",
      "200/200 [==============================] - 2s 8ms/step - loss: 2.1689e-05\n",
      "Epoch 96/100\n",
      "200/200 [==============================] - 2s 8ms/step - loss: 2.0938e-05\n",
      "Epoch 97/100\n",
      "200/200 [==============================] - 2s 8ms/step - loss: 2.1266e-05\n",
      "Epoch 98/100\n",
      "200/200 [==============================] - 2s 8ms/step - loss: 2.1122e-05\n",
      "Epoch 99/100\n",
      "200/200 [==============================] - 2s 8ms/step - loss: 2.0866e-05\n",
      "Epoch 100/100\n",
      "200/200 [==============================] - 2s 8ms/step - loss: 2.0679e-05\n",
      "INFO:tensorflow:Assets written to: DistanceEncoderWeights/assets\n"
     ]
    }
   ],
   "source": [
    "if os.path.isdir(\"DistanceEncoderWeights\"):\n",
    "    pass\n",
    "else:\n",
    "    autoencoder.fit(MissingDataSet,FullDataSet,\n",
    "                    epochs=1000,\n",
    "                    shuffle=True,\n",
    "                   batch_size=5)\n",
    "    autoencoder.save(\"DistanceEncoderWeights\")"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50/50 [==============================] - 0s 9ms/step - loss: 2.1220e-05\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "2.1219560949248262e-05"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "autoencoder.evaluate(MissingDataSet,FullDataSet,20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 24, 24, 1)"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Test=MissingDataset[tf.newaxis,0,...,tf.newaxis]\n",
    "np.shape(Test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "Export=autoencoder.predict(Test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "Export=pd.DataFrame(np.reshape(Export,(24,24)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "Export=Export-np.diag(np.diag(Export))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "Export.to_csv(\"Example_Output.csv\",index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>14</th>\n",
       "      <th>15</th>\n",
       "      <th>16</th>\n",
       "      <th>17</th>\n",
       "      <th>18</th>\n",
       "      <th>19</th>\n",
       "      <th>20</th>\n",
       "      <th>21</th>\n",
       "      <th>22</th>\n",
       "      <th>23</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.003623</td>\n",
       "      <td>0.142437</td>\n",
       "      <td>0.145649</td>\n",
       "      <td>0.142419</td>\n",
       "      <td>0.149034</td>\n",
       "      <td>0.136620</td>\n",
       "      <td>0.139350</td>\n",
       "      <td>0.139793</td>\n",
       "      <td>0.140135</td>\n",
       "      <td>...</td>\n",
       "      <td>0.139119</td>\n",
       "      <td>0.139266</td>\n",
       "      <td>0.139463</td>\n",
       "      <td>0.139042</td>\n",
       "      <td>0.144736</td>\n",
       "      <td>0.150596</td>\n",
       "      <td>0.146167</td>\n",
       "      <td>0.132792</td>\n",
       "      <td>0.137168</td>\n",
       "      <td>0.159829</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.003123</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.141730</td>\n",
       "      <td>0.144568</td>\n",
       "      <td>0.140405</td>\n",
       "      <td>0.149824</td>\n",
       "      <td>0.136857</td>\n",
       "      <td>0.126401</td>\n",
       "      <td>0.135979</td>\n",
       "      <td>0.138560</td>\n",
       "      <td>...</td>\n",
       "      <td>0.142382</td>\n",
       "      <td>0.142423</td>\n",
       "      <td>0.140747</td>\n",
       "      <td>0.138226</td>\n",
       "      <td>0.145138</td>\n",
       "      <td>0.150843</td>\n",
       "      <td>0.146769</td>\n",
       "      <td>0.133890</td>\n",
       "      <td>0.138145</td>\n",
       "      <td>0.160025</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.143705</td>\n",
       "      <td>0.144996</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.009571</td>\n",
       "      <td>0.101024</td>\n",
       "      <td>0.109476</td>\n",
       "      <td>0.046051</td>\n",
       "      <td>0.039875</td>\n",
       "      <td>0.063783</td>\n",
       "      <td>0.072136</td>\n",
       "      <td>...</td>\n",
       "      <td>0.090224</td>\n",
       "      <td>0.088554</td>\n",
       "      <td>0.086720</td>\n",
       "      <td>0.081333</td>\n",
       "      <td>0.094052</td>\n",
       "      <td>0.093878</td>\n",
       "      <td>0.095601</td>\n",
       "      <td>0.147290</td>\n",
       "      <td>0.138981</td>\n",
       "      <td>0.153711</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.143658</td>\n",
       "      <td>0.143738</td>\n",
       "      <td>0.009627</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.100538</td>\n",
       "      <td>0.109465</td>\n",
       "      <td>0.044087</td>\n",
       "      <td>0.040454</td>\n",
       "      <td>0.056715</td>\n",
       "      <td>0.061589</td>\n",
       "      <td>...</td>\n",
       "      <td>0.089167</td>\n",
       "      <td>0.086933</td>\n",
       "      <td>0.088307</td>\n",
       "      <td>0.086962</td>\n",
       "      <td>0.094011</td>\n",
       "      <td>0.089735</td>\n",
       "      <td>0.093568</td>\n",
       "      <td>0.145506</td>\n",
       "      <td>0.139421</td>\n",
       "      <td>0.153051</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.144417</td>\n",
       "      <td>0.142600</td>\n",
       "      <td>0.099644</td>\n",
       "      <td>0.099534</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.046990</td>\n",
       "      <td>0.094092</td>\n",
       "      <td>0.082044</td>\n",
       "      <td>0.091529</td>\n",
       "      <td>0.092154</td>\n",
       "      <td>...</td>\n",
       "      <td>0.083691</td>\n",
       "      <td>0.085006</td>\n",
       "      <td>0.086395</td>\n",
       "      <td>0.085135</td>\n",
       "      <td>0.093065</td>\n",
       "      <td>0.091127</td>\n",
       "      <td>0.093517</td>\n",
       "      <td>0.146183</td>\n",
       "      <td>0.137286</td>\n",
       "      <td>0.151447</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.149461</td>\n",
       "      <td>0.148548</td>\n",
       "      <td>0.103876</td>\n",
       "      <td>0.105187</td>\n",
       "      <td>0.044729</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.098451</td>\n",
       "      <td>0.090514</td>\n",
       "      <td>0.092196</td>\n",
       "      <td>0.095699</td>\n",
       "      <td>...</td>\n",
       "      <td>0.088627</td>\n",
       "      <td>0.088910</td>\n",
       "      <td>0.088574</td>\n",
       "      <td>0.088244</td>\n",
       "      <td>0.095946</td>\n",
       "      <td>0.093876</td>\n",
       "      <td>0.099595</td>\n",
       "      <td>0.148696</td>\n",
       "      <td>0.138001</td>\n",
       "      <td>0.153592</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.132525</td>\n",
       "      <td>0.136172</td>\n",
       "      <td>0.047774</td>\n",
       "      <td>0.047564</td>\n",
       "      <td>0.094628</td>\n",
       "      <td>0.081407</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.025316</td>\n",
       "      <td>0.057896</td>\n",
       "      <td>0.061415</td>\n",
       "      <td>...</td>\n",
       "      <td>0.084096</td>\n",
       "      <td>0.083811</td>\n",
       "      <td>0.083311</td>\n",
       "      <td>0.083743</td>\n",
       "      <td>0.087158</td>\n",
       "      <td>0.088506</td>\n",
       "      <td>0.091926</td>\n",
       "      <td>0.145874</td>\n",
       "      <td>0.136436</td>\n",
       "      <td>0.152200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.128526</td>\n",
       "      <td>0.126289</td>\n",
       "      <td>0.041428</td>\n",
       "      <td>0.041031</td>\n",
       "      <td>0.076114</td>\n",
       "      <td>0.084758</td>\n",
       "      <td>0.025361</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.041557</td>\n",
       "      <td>0.057206</td>\n",
       "      <td>...</td>\n",
       "      <td>0.083852</td>\n",
       "      <td>0.084457</td>\n",
       "      <td>0.083336</td>\n",
       "      <td>0.084003</td>\n",
       "      <td>0.088933</td>\n",
       "      <td>0.089882</td>\n",
       "      <td>0.090137</td>\n",
       "      <td>0.146843</td>\n",
       "      <td>0.136917</td>\n",
       "      <td>0.153001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.139786</td>\n",
       "      <td>0.136889</td>\n",
       "      <td>0.066687</td>\n",
       "      <td>0.059244</td>\n",
       "      <td>0.090650</td>\n",
       "      <td>0.092454</td>\n",
       "      <td>0.060210</td>\n",
       "      <td>0.049687</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.012893</td>\n",
       "      <td>...</td>\n",
       "      <td>0.084513</td>\n",
       "      <td>0.085273</td>\n",
       "      <td>0.084371</td>\n",
       "      <td>0.084017</td>\n",
       "      <td>0.090274</td>\n",
       "      <td>0.090134</td>\n",
       "      <td>0.090700</td>\n",
       "      <td>0.146618</td>\n",
       "      <td>0.137030</td>\n",
       "      <td>0.153174</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.140636</td>\n",
       "      <td>0.139927</td>\n",
       "      <td>0.072664</td>\n",
       "      <td>0.063231</td>\n",
       "      <td>0.087718</td>\n",
       "      <td>0.090364</td>\n",
       "      <td>0.061650</td>\n",
       "      <td>0.060400</td>\n",
       "      <td>0.013361</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.082055</td>\n",
       "      <td>0.084556</td>\n",
       "      <td>0.083699</td>\n",
       "      <td>0.083227</td>\n",
       "      <td>0.089479</td>\n",
       "      <td>0.089262</td>\n",
       "      <td>0.090339</td>\n",
       "      <td>0.146936</td>\n",
       "      <td>0.137269</td>\n",
       "      <td>0.153111</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.141616</td>\n",
       "      <td>0.142272</td>\n",
       "      <td>0.082236</td>\n",
       "      <td>0.077244</td>\n",
       "      <td>0.090375</td>\n",
       "      <td>0.092379</td>\n",
       "      <td>0.077394</td>\n",
       "      <td>0.071474</td>\n",
       "      <td>0.065052</td>\n",
       "      <td>0.050533</td>\n",
       "      <td>...</td>\n",
       "      <td>0.083844</td>\n",
       "      <td>0.082695</td>\n",
       "      <td>0.084252</td>\n",
       "      <td>0.082792</td>\n",
       "      <td>0.089674</td>\n",
       "      <td>0.087637</td>\n",
       "      <td>0.089940</td>\n",
       "      <td>0.147093</td>\n",
       "      <td>0.137584</td>\n",
       "      <td>0.153328</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.142819</td>\n",
       "      <td>0.143988</td>\n",
       "      <td>0.083626</td>\n",
       "      <td>0.087098</td>\n",
       "      <td>0.088150</td>\n",
       "      <td>0.094172</td>\n",
       "      <td>0.079275</td>\n",
       "      <td>0.082683</td>\n",
       "      <td>0.076834</td>\n",
       "      <td>0.070359</td>\n",
       "      <td>...</td>\n",
       "      <td>0.078301</td>\n",
       "      <td>0.075861</td>\n",
       "      <td>0.079293</td>\n",
       "      <td>0.079907</td>\n",
       "      <td>0.074375</td>\n",
       "      <td>0.088182</td>\n",
       "      <td>0.088814</td>\n",
       "      <td>0.147347</td>\n",
       "      <td>0.138188</td>\n",
       "      <td>0.153477</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.143181</td>\n",
       "      <td>0.144165</td>\n",
       "      <td>0.085361</td>\n",
       "      <td>0.087488</td>\n",
       "      <td>0.087660</td>\n",
       "      <td>0.092569</td>\n",
       "      <td>0.088144</td>\n",
       "      <td>0.083511</td>\n",
       "      <td>0.080967</td>\n",
       "      <td>0.078287</td>\n",
       "      <td>...</td>\n",
       "      <td>0.057937</td>\n",
       "      <td>0.056793</td>\n",
       "      <td>0.058542</td>\n",
       "      <td>0.050823</td>\n",
       "      <td>0.051992</td>\n",
       "      <td>0.049675</td>\n",
       "      <td>0.064799</td>\n",
       "      <td>0.148025</td>\n",
       "      <td>0.138779</td>\n",
       "      <td>0.153485</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0.140576</td>\n",
       "      <td>0.141697</td>\n",
       "      <td>0.086901</td>\n",
       "      <td>0.090659</td>\n",
       "      <td>0.086998</td>\n",
       "      <td>0.094214</td>\n",
       "      <td>0.083145</td>\n",
       "      <td>0.086586</td>\n",
       "      <td>0.079679</td>\n",
       "      <td>0.076545</td>\n",
       "      <td>...</td>\n",
       "      <td>0.047676</td>\n",
       "      <td>0.053437</td>\n",
       "      <td>0.057328</td>\n",
       "      <td>0.050089</td>\n",
       "      <td>0.049742</td>\n",
       "      <td>0.049235</td>\n",
       "      <td>0.061659</td>\n",
       "      <td>0.148552</td>\n",
       "      <td>0.139494</td>\n",
       "      <td>0.153283</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0.139630</td>\n",
       "      <td>0.141841</td>\n",
       "      <td>0.086894</td>\n",
       "      <td>0.089316</td>\n",
       "      <td>0.086564</td>\n",
       "      <td>0.093906</td>\n",
       "      <td>0.083604</td>\n",
       "      <td>0.083675</td>\n",
       "      <td>0.088289</td>\n",
       "      <td>0.083415</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.003124</td>\n",
       "      <td>0.018188</td>\n",
       "      <td>0.018716</td>\n",
       "      <td>0.050665</td>\n",
       "      <td>0.047664</td>\n",
       "      <td>0.059139</td>\n",
       "      <td>0.148415</td>\n",
       "      <td>0.138970</td>\n",
       "      <td>0.153135</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0.140031</td>\n",
       "      <td>0.141119</td>\n",
       "      <td>0.086721</td>\n",
       "      <td>0.087859</td>\n",
       "      <td>0.087337</td>\n",
       "      <td>0.091851</td>\n",
       "      <td>0.083746</td>\n",
       "      <td>0.084224</td>\n",
       "      <td>0.083195</td>\n",
       "      <td>0.084568</td>\n",
       "      <td>...</td>\n",
       "      <td>0.003554</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.012657</td>\n",
       "      <td>0.014946</td>\n",
       "      <td>0.049237</td>\n",
       "      <td>0.049705</td>\n",
       "      <td>0.060049</td>\n",
       "      <td>0.148481</td>\n",
       "      <td>0.137642</td>\n",
       "      <td>0.152762</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0.141194</td>\n",
       "      <td>0.141480</td>\n",
       "      <td>0.085498</td>\n",
       "      <td>0.087798</td>\n",
       "      <td>0.086621</td>\n",
       "      <td>0.091692</td>\n",
       "      <td>0.082968</td>\n",
       "      <td>0.083994</td>\n",
       "      <td>0.083367</td>\n",
       "      <td>0.082522</td>\n",
       "      <td>...</td>\n",
       "      <td>0.021571</td>\n",
       "      <td>0.014661</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.003725</td>\n",
       "      <td>0.055031</td>\n",
       "      <td>0.045630</td>\n",
       "      <td>0.059185</td>\n",
       "      <td>0.142154</td>\n",
       "      <td>0.134228</td>\n",
       "      <td>0.152170</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>0.142042</td>\n",
       "      <td>0.141379</td>\n",
       "      <td>0.084194</td>\n",
       "      <td>0.086952</td>\n",
       "      <td>0.085358</td>\n",
       "      <td>0.093907</td>\n",
       "      <td>0.084238</td>\n",
       "      <td>0.084884</td>\n",
       "      <td>0.084927</td>\n",
       "      <td>0.084419</td>\n",
       "      <td>...</td>\n",
       "      <td>0.021478</td>\n",
       "      <td>0.016991</td>\n",
       "      <td>0.004054</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.050271</td>\n",
       "      <td>0.050651</td>\n",
       "      <td>0.062880</td>\n",
       "      <td>0.143925</td>\n",
       "      <td>0.134789</td>\n",
       "      <td>0.150530</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>0.146386</td>\n",
       "      <td>0.145640</td>\n",
       "      <td>0.095541</td>\n",
       "      <td>0.096092</td>\n",
       "      <td>0.093334</td>\n",
       "      <td>0.093503</td>\n",
       "      <td>0.087855</td>\n",
       "      <td>0.087706</td>\n",
       "      <td>0.089450</td>\n",
       "      <td>0.090492</td>\n",
       "      <td>...</td>\n",
       "      <td>0.050115</td>\n",
       "      <td>0.055952</td>\n",
       "      <td>0.056275</td>\n",
       "      <td>0.050557</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.014148</td>\n",
       "      <td>0.057301</td>\n",
       "      <td>0.151605</td>\n",
       "      <td>0.140586</td>\n",
       "      <td>0.154317</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>0.151948</td>\n",
       "      <td>0.152988</td>\n",
       "      <td>0.094030</td>\n",
       "      <td>0.092356</td>\n",
       "      <td>0.092359</td>\n",
       "      <td>0.100846</td>\n",
       "      <td>0.092726</td>\n",
       "      <td>0.088932</td>\n",
       "      <td>0.090407</td>\n",
       "      <td>0.092583</td>\n",
       "      <td>...</td>\n",
       "      <td>0.050092</td>\n",
       "      <td>0.052432</td>\n",
       "      <td>0.055027</td>\n",
       "      <td>0.057749</td>\n",
       "      <td>0.013982</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.050974</td>\n",
       "      <td>0.149393</td>\n",
       "      <td>0.142756</td>\n",
       "      <td>0.155427</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>0.147385</td>\n",
       "      <td>0.147795</td>\n",
       "      <td>0.095149</td>\n",
       "      <td>0.092274</td>\n",
       "      <td>0.093040</td>\n",
       "      <td>0.102717</td>\n",
       "      <td>0.093559</td>\n",
       "      <td>0.089634</td>\n",
       "      <td>0.091411</td>\n",
       "      <td>0.093853</td>\n",
       "      <td>...</td>\n",
       "      <td>0.062933</td>\n",
       "      <td>0.059250</td>\n",
       "      <td>0.060287</td>\n",
       "      <td>0.059979</td>\n",
       "      <td>0.053537</td>\n",
       "      <td>0.053155</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.145431</td>\n",
       "      <td>0.140276</td>\n",
       "      <td>0.153345</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>0.132460</td>\n",
       "      <td>0.133088</td>\n",
       "      <td>0.145934</td>\n",
       "      <td>0.137690</td>\n",
       "      <td>0.144364</td>\n",
       "      <td>0.150086</td>\n",
       "      <td>0.146658</td>\n",
       "      <td>0.145763</td>\n",
       "      <td>0.149398</td>\n",
       "      <td>0.149245</td>\n",
       "      <td>...</td>\n",
       "      <td>0.147171</td>\n",
       "      <td>0.145519</td>\n",
       "      <td>0.144778</td>\n",
       "      <td>0.143149</td>\n",
       "      <td>0.152490</td>\n",
       "      <td>0.151434</td>\n",
       "      <td>0.135568</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.146500</td>\n",
       "      <td>0.157898</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>0.137385</td>\n",
       "      <td>0.138153</td>\n",
       "      <td>0.139649</td>\n",
       "      <td>0.140381</td>\n",
       "      <td>0.137815</td>\n",
       "      <td>0.139253</td>\n",
       "      <td>0.136185</td>\n",
       "      <td>0.136282</td>\n",
       "      <td>0.138567</td>\n",
       "      <td>0.139459</td>\n",
       "      <td>...</td>\n",
       "      <td>0.141119</td>\n",
       "      <td>0.135280</td>\n",
       "      <td>0.133590</td>\n",
       "      <td>0.134137</td>\n",
       "      <td>0.142229</td>\n",
       "      <td>0.141453</td>\n",
       "      <td>0.140374</td>\n",
       "      <td>0.142901</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.160736</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>0.159760</td>\n",
       "      <td>0.160358</td>\n",
       "      <td>0.153217</td>\n",
       "      <td>0.152734</td>\n",
       "      <td>0.151395</td>\n",
       "      <td>0.154542</td>\n",
       "      <td>0.153503</td>\n",
       "      <td>0.152568</td>\n",
       "      <td>0.153020</td>\n",
       "      <td>0.153149</td>\n",
       "      <td>...</td>\n",
       "      <td>0.152543</td>\n",
       "      <td>0.153110</td>\n",
       "      <td>0.149241</td>\n",
       "      <td>0.149894</td>\n",
       "      <td>0.154394</td>\n",
       "      <td>0.155074</td>\n",
       "      <td>0.153905</td>\n",
       "      <td>0.159992</td>\n",
       "      <td>0.160066</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>24 rows Ã— 24 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          0         1         2         3         4         5         6   \\\n",
       "0   0.000000  0.003623  0.142437  0.145649  0.142419  0.149034  0.136620   \n",
       "1   0.003123  0.000000  0.141730  0.144568  0.140405  0.149824  0.136857   \n",
       "2   0.143705  0.144996  0.000000  0.009571  0.101024  0.109476  0.046051   \n",
       "3   0.143658  0.143738  0.009627  0.000000  0.100538  0.109465  0.044087   \n",
       "4   0.144417  0.142600  0.099644  0.099534  0.000000  0.046990  0.094092   \n",
       "5   0.149461  0.148548  0.103876  0.105187  0.044729  0.000000  0.098451   \n",
       "6   0.132525  0.136172  0.047774  0.047564  0.094628  0.081407  0.000000   \n",
       "7   0.128526  0.126289  0.041428  0.041031  0.076114  0.084758  0.025361   \n",
       "8   0.139786  0.136889  0.066687  0.059244  0.090650  0.092454  0.060210   \n",
       "9   0.140636  0.139927  0.072664  0.063231  0.087718  0.090364  0.061650   \n",
       "10  0.141616  0.142272  0.082236  0.077244  0.090375  0.092379  0.077394   \n",
       "11  0.142819  0.143988  0.083626  0.087098  0.088150  0.094172  0.079275   \n",
       "12  0.143181  0.144165  0.085361  0.087488  0.087660  0.092569  0.088144   \n",
       "13  0.140576  0.141697  0.086901  0.090659  0.086998  0.094214  0.083145   \n",
       "14  0.139630  0.141841  0.086894  0.089316  0.086564  0.093906  0.083604   \n",
       "15  0.140031  0.141119  0.086721  0.087859  0.087337  0.091851  0.083746   \n",
       "16  0.141194  0.141480  0.085498  0.087798  0.086621  0.091692  0.082968   \n",
       "17  0.142042  0.141379  0.084194  0.086952  0.085358  0.093907  0.084238   \n",
       "18  0.146386  0.145640  0.095541  0.096092  0.093334  0.093503  0.087855   \n",
       "19  0.151948  0.152988  0.094030  0.092356  0.092359  0.100846  0.092726   \n",
       "20  0.147385  0.147795  0.095149  0.092274  0.093040  0.102717  0.093559   \n",
       "21  0.132460  0.133088  0.145934  0.137690  0.144364  0.150086  0.146658   \n",
       "22  0.137385  0.138153  0.139649  0.140381  0.137815  0.139253  0.136185   \n",
       "23  0.159760  0.160358  0.153217  0.152734  0.151395  0.154542  0.153503   \n",
       "\n",
       "          7         8         9   ...        14        15        16        17  \\\n",
       "0   0.139350  0.139793  0.140135  ...  0.139119  0.139266  0.139463  0.139042   \n",
       "1   0.126401  0.135979  0.138560  ...  0.142382  0.142423  0.140747  0.138226   \n",
       "2   0.039875  0.063783  0.072136  ...  0.090224  0.088554  0.086720  0.081333   \n",
       "3   0.040454  0.056715  0.061589  ...  0.089167  0.086933  0.088307  0.086962   \n",
       "4   0.082044  0.091529  0.092154  ...  0.083691  0.085006  0.086395  0.085135   \n",
       "5   0.090514  0.092196  0.095699  ...  0.088627  0.088910  0.088574  0.088244   \n",
       "6   0.025316  0.057896  0.061415  ...  0.084096  0.083811  0.083311  0.083743   \n",
       "7   0.000000  0.041557  0.057206  ...  0.083852  0.084457  0.083336  0.084003   \n",
       "8   0.049687  0.000000  0.012893  ...  0.084513  0.085273  0.084371  0.084017   \n",
       "9   0.060400  0.013361  0.000000  ...  0.082055  0.084556  0.083699  0.083227   \n",
       "10  0.071474  0.065052  0.050533  ...  0.083844  0.082695  0.084252  0.082792   \n",
       "11  0.082683  0.076834  0.070359  ...  0.078301  0.075861  0.079293  0.079907   \n",
       "12  0.083511  0.080967  0.078287  ...  0.057937  0.056793  0.058542  0.050823   \n",
       "13  0.086586  0.079679  0.076545  ...  0.047676  0.053437  0.057328  0.050089   \n",
       "14  0.083675  0.088289  0.083415  ...  0.000000  0.003124  0.018188  0.018716   \n",
       "15  0.084224  0.083195  0.084568  ...  0.003554  0.000000  0.012657  0.014946   \n",
       "16  0.083994  0.083367  0.082522  ...  0.021571  0.014661  0.000000  0.003725   \n",
       "17  0.084884  0.084927  0.084419  ...  0.021478  0.016991  0.004054  0.000000   \n",
       "18  0.087706  0.089450  0.090492  ...  0.050115  0.055952  0.056275  0.050557   \n",
       "19  0.088932  0.090407  0.092583  ...  0.050092  0.052432  0.055027  0.057749   \n",
       "20  0.089634  0.091411  0.093853  ...  0.062933  0.059250  0.060287  0.059979   \n",
       "21  0.145763  0.149398  0.149245  ...  0.147171  0.145519  0.144778  0.143149   \n",
       "22  0.136282  0.138567  0.139459  ...  0.141119  0.135280  0.133590  0.134137   \n",
       "23  0.152568  0.153020  0.153149  ...  0.152543  0.153110  0.149241  0.149894   \n",
       "\n",
       "          18        19        20        21        22        23  \n",
       "0   0.144736  0.150596  0.146167  0.132792  0.137168  0.159829  \n",
       "1   0.145138  0.150843  0.146769  0.133890  0.138145  0.160025  \n",
       "2   0.094052  0.093878  0.095601  0.147290  0.138981  0.153711  \n",
       "3   0.094011  0.089735  0.093568  0.145506  0.139421  0.153051  \n",
       "4   0.093065  0.091127  0.093517  0.146183  0.137286  0.151447  \n",
       "5   0.095946  0.093876  0.099595  0.148696  0.138001  0.153592  \n",
       "6   0.087158  0.088506  0.091926  0.145874  0.136436  0.152200  \n",
       "7   0.088933  0.089882  0.090137  0.146843  0.136917  0.153001  \n",
       "8   0.090274  0.090134  0.090700  0.146618  0.137030  0.153174  \n",
       "9   0.089479  0.089262  0.090339  0.146936  0.137269  0.153111  \n",
       "10  0.089674  0.087637  0.089940  0.147093  0.137584  0.153328  \n",
       "11  0.074375  0.088182  0.088814  0.147347  0.138188  0.153477  \n",
       "12  0.051992  0.049675  0.064799  0.148025  0.138779  0.153485  \n",
       "13  0.049742  0.049235  0.061659  0.148552  0.139494  0.153283  \n",
       "14  0.050665  0.047664  0.059139  0.148415  0.138970  0.153135  \n",
       "15  0.049237  0.049705  0.060049  0.148481  0.137642  0.152762  \n",
       "16  0.055031  0.045630  0.059185  0.142154  0.134228  0.152170  \n",
       "17  0.050271  0.050651  0.062880  0.143925  0.134789  0.150530  \n",
       "18  0.000000  0.014148  0.057301  0.151605  0.140586  0.154317  \n",
       "19  0.013982  0.000000  0.050974  0.149393  0.142756  0.155427  \n",
       "20  0.053537  0.053155  0.000000  0.145431  0.140276  0.153345  \n",
       "21  0.152490  0.151434  0.135568  0.000000  0.146500  0.157898  \n",
       "22  0.142229  0.141453  0.140374  0.142901  0.000000  0.160736  \n",
       "23  0.154394  0.155074  0.153905  0.159992  0.160066  0.000000  \n",
       "\n",
       "[24 rows x 24 columns]"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Export"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_tensorflow2_p36",
   "language": "python",
   "name": "conda_tensorflow2_p36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
